#!/usr/bin/env python3
"""
ã‚¹ãƒãƒ¼ãƒˆTTSç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸè‡ªå‹•åˆ†å‰²ã¨çµåˆã§ã€é•·ã„å°æœ¬ã‚‚1ã¤ã®MP3ãƒ•ã‚¡ã‚¤ãƒ«ã«
"""

import os
import json
import re
import tempfile
import subprocess
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from pathlib import Path

# Google Cloud TTS ã‚’ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from google.cloud import texttospeech
    GOOGLE_TTS_AVAILABLE = True
except ImportError:
    GOOGLE_TTS_AVAILABLE = False
    print("Warning: google-cloud-texttospeech not installed.")


class SmartTTSGenerator:
    """ã‚¹ãƒãƒ¼ãƒˆãªTTSç”Ÿæˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, credentials_path: Optional[str] = None):
        """
        Args:
            credentials_path: Google Cloudèªè¨¼JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        # èªè¨¼ãƒ‘ã‚¹ã®å„ªå…ˆé †ä½:
        # 1. å¼•æ•°ã§æ˜ç¤ºçš„ã«æŒ‡å®š
        # 2. ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS
        # 3. .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        # 4. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç’°å¢ƒã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹

        if credentials_path:
            self.credentials_path = credentials_path
        elif os.environ.get('GOOGLE_APPLICATION_CREDENTIALS'):
            self.credentials_path = os.environ['GOOGLE_APPLICATION_CREDENTIALS']
        else:
            # .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã—ã¦èª­ã¿è¾¼ã¿
            self._load_env_file()
            self.credentials_path = os.environ.get(
                'GOOGLE_APPLICATION_CREDENTIALS',
                os.path.expanduser("~/Desktop/git-worktree-agent/credentials/gcp-workflow-key.json")
            )

        self.client = None
        self.max_bytes = 4500  # 5000ãƒã‚¤ãƒˆåˆ¶é™ã‚ˆã‚Šå°‘ã—å°ã•ã‚

        if GOOGLE_TTS_AVAILABLE and os.path.exists(self.credentials_path):
            self._initialize_client()

    def _load_env_file(self):
        """ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã—ã¦èª­ã¿è¾¼ã¿"""
        try:
            from dotenv import load_dotenv

            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® .env
            if os.path.exists('.env'):
                load_dotenv('.env')
                return

            # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® .env
            if os.path.exists('../.env'):
                load_dotenv('../.env')
                return

        except ImportError:
            # dotenvãŒãªã„å ´åˆã¯æ‰‹å‹•ã§èª­ã¿è¾¼ã¿
            env_paths = ['.env', '../.env']
            for env_path in env_paths:
                if os.path.exists(env_path):
                    with open(env_path, 'r') as f:
                        for line in f:
                            line = line.strip()
                            if line and not line.startswith('#') and '=' in line:
                                key, value = line.split('=', 1)
                                # ~ ã‚’å±•é–‹
                                value = os.path.expanduser(value.strip())
                                os.environ[key.strip()] = value
                    return

    def _initialize_client(self):
        """Google TTS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = self.credentials_path
        self.client = texttospeech.TextToSpeechClient()
        print("âœ… Google TTS client initialized")

    def split_text_by_context(self, text: str, is_ssml: bool = False) -> List[str]:
        """
        æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²

        Args:
            text: åˆ†å‰²ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            is_ssml: SSMLå½¢å¼ã‹ã©ã†ã‹

        Returns:
            åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        chunks = []
        current_chunk = ""

        if is_ssml:
            # SSMLã‚¿ã‚°ã‚’ä¸€æ™‚çš„ã«å‰Šé™¤ã—ã¦åˆ†å‰²å‡¦ç†
            text = re.sub(r'<speak>|</speak>', '', text)

        # å„ªå…ˆåº¦é †ã®åŒºåˆ‡ã‚Šæ–‡å­—
        # 1. ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Šï¼ˆbreakã‚¿ã‚¤ãƒ ãŒé•·ã„ã‚‚ã®ï¼‰
        # 2. æ®µè½åŒºåˆ‡ã‚Šï¼ˆæ”¹è¡Œ2ã¤ä»¥ä¸Šï¼‰
        # 3. æ–‡ã®åŒºåˆ‡ã‚Šï¼ˆå¥ç‚¹ï¼‰
        # 4. æ”¹è¡Œ

        # ã¾ãšå¤§ããªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§åˆ†å‰²ã‚’è©¦ã¿ã‚‹
        sections = re.split(r'<break time="[1-9]\d*s"/>', text)

        for section in sections:
            if not section.strip():
                continue

            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒåˆ¶é™å†…ãªã‚‰è¿½åŠ 
            if self._get_byte_size(current_chunk + section) <= self.max_bytes:
                current_chunk += section
                if section != sections[-1]:  # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä»¥å¤–
                    current_chunk += '<break time="1s"/>'
            else:
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå¤§ãã™ãã‚‹å ´åˆã¯æ®µè½ã§åˆ†å‰²
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = ""

                # æ®µè½ã§åˆ†å‰²
                paragraphs = section.split('\n\n')
                for paragraph in paragraphs:
                    if self._get_byte_size(current_chunk + paragraph) <= self.max_bytes:
                        current_chunk += paragraph + '\n\n'
                    else:
                        # æ®µè½ã‚‚å¤§ãã™ãã‚‹å ´åˆã¯æ–‡ã§åˆ†å‰²
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                            current_chunk = ""

                        sentences = self._split_by_sentence(paragraph)
                        for sentence in sentences:
                            if self._get_byte_size(current_chunk + sentence) <= self.max_bytes:
                                current_chunk += sentence
                            else:
                                if current_chunk:
                                    chunks.append(current_chunk.strip())
                                current_chunk = sentence

        # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
        if current_chunk.strip():
            chunks.append(current_chunk.strip())

        # SSMLã®å ´åˆã¯å„ãƒãƒ£ãƒ³ã‚¯ã«<speak>ã‚¿ã‚°ã‚’è¿½åŠ 
        if is_ssml:
            chunks = [f'<speak>{chunk}</speak>' for chunk in chunks]

        return chunks

    def _split_by_sentence(self, text: str) -> List[str]:
        """æ–‡å˜ä½ã§åˆ†å‰²"""
        # æ—¥æœ¬èªã®å¥ç‚¹ã§åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)

        # å¥èª­ç‚¹ã‚’æ–‡ã«å«ã‚ã‚‹
        result = []
        for i in range(0, len(sentences), 2):
            if i + 1 < len(sentences):
                result.append(sentences[i] + sentences[i + 1])
            else:
                result.append(sentences[i])

        return [s for s in result if s.strip()]

    def _get_byte_size(self, text: str) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒã‚¤ãƒˆã‚µã‚¤ã‚ºã‚’å–å¾—"""
        return len(text.encode('utf-8'))

    def generate_audio_chunks(self,
                            chunks: List[str],
                            voice_config: Optional[Dict] = None,
                            is_ssml: bool = False) -> List[str]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ

        Args:
            chunks: ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
            voice_config: éŸ³å£°è¨­å®š
            is_ssml: SSMLå½¢å¼ã‹ã©ã†ã‹

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        if not self.client:
            print("âŒ TTS client not initialized")
            return []

        temp_files = []

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®éŸ³å£°è¨­å®š
        if voice_config is None:
            voice_config = {
                "language_code": "ja-JP",
                "name": "ja-JP-Wavenet-B",
                "ssml_gender": "MALE"
            }

        print(f"ğŸ“ {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ä¸­...")

        for i, chunk in enumerate(chunks):
            print(f"  ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(chunks)} ã‚’ç”Ÿæˆä¸­...")

            try:
                # éŸ³å£°åˆæˆã®å…¥åŠ›
                if is_ssml:
                    synthesis_input = texttospeech.SynthesisInput(ssml=chunk)
                else:
                    synthesis_input = texttospeech.SynthesisInput(text=chunk)

                # éŸ³å£°è¨­å®š
                voice = texttospeech.VoiceSelectionParams(
                    language_code=voice_config.get('language_code', 'ja-JP'),
                    name=voice_config.get('name', 'ja-JP-Wavenet-B')
                )

                audio_config = texttospeech.AudioConfig(
                    audio_encoding=texttospeech.AudioEncoding.MP3,
                    speaking_rate=voice_config.get('speaking_rate', 1.0),
                    pitch=voice_config.get('pitch', 0.0),
                    volume_gain_db=voice_config.get('volume_gain_db', 0.0)
                )

                # APIå‘¼ã³å‡ºã—
                response = self.client.synthesize_speech(
                    input=synthesis_input,
                    voice=voice,
                    audio_config=audio_config
                )

                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                temp_file = tempfile.NamedTemporaryFile(
                    suffix=f'_chunk_{i}.mp3',
                    delete=False,
                    dir=tempfile.gettempdir()
                )
                temp_file.write(response.audio_content)
                temp_file.close()
                temp_files.append(temp_file.name)

                print(f"    âœ… ãƒãƒ£ãƒ³ã‚¯ {i+1} å®Œäº† ({len(response.audio_content) / 1024:.2f} KB)")

            except Exception as e:
                print(f"    âŒ ãƒãƒ£ãƒ³ã‚¯ {i+1} ã‚¨ãƒ©ãƒ¼: {e}")

        return temp_files

    def merge_audio_files(self, audio_files: List[str], output_path: str) -> bool:
        """
        è¤‡æ•°ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ

        Args:
            audio_files: çµåˆã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        if not audio_files:
            print("âŒ çµåˆã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            return False

        try:
            # ffmpegãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
            result = subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True)
            has_ffmpeg = result.returncode == 0

            if has_ffmpeg:
                # ffmpegã‚’ä½¿ç”¨ã—ã¦çµåˆ
                print("ğŸ”§ ffmpegã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆä¸­...")

                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ä½œæˆ
                list_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
                for audio_file in audio_files:
                    list_file.write(f"file '{audio_file}'\n")
                list_file.close()

                # ffmpegã§çµåˆ
                cmd = [
                    'ffmpeg', '-f', 'concat', '-safe', '0',
                    '-i', list_file.name,
                    '-c', 'copy',
                    '-y',  # ä¸Šæ›¸ãç¢ºèªãªã—
                    output_path
                ]

                result = subprocess.run(cmd, capture_output=True, text=True)
                os.unlink(list_file.name)

                if result.returncode == 0:
                    print(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã—ã¾ã—ãŸ: {output_path}")
                    return True
                else:
                    print(f"âŒ ffmpegçµåˆã‚¨ãƒ©ãƒ¼: {result.stderr}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    return self._merge_with_python(audio_files, output_path)

            else:
                # ffmpegãŒãªã„å ´åˆã¯Pythonã§çµåˆ
                return self._merge_with_python(audio_files, output_path)

        except Exception as e:
            print(f"âŒ çµåˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _merge_with_python(self, audio_files: List[str], output_path: str) -> bool:
        """Pythonã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        print("ğŸ”§ Pythonã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆä¸­...")

        try:
            with open(output_path, 'wb') as output:
                for audio_file in audio_files:
                    with open(audio_file, 'rb') as input_file:
                        output.write(input_file.read())

            print(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã—ã¾ã—ãŸ: {output_path}")
            return True

        except Exception as e:
            print(f"âŒ Pythonçµåˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def generate_from_text(self,
                          text: str,
                          output_path: str,
                          voice_config: Optional[Dict] = None,
                          cleanup: bool = True) -> Tuple[bool, Dict]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰

        Args:
            text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯SSMLï¼‰
            output_path: å‡ºåŠ›MP3ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            voice_config: éŸ³å£°è¨­å®š
            cleanup: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹ã‹

        Returns:
            (æˆåŠŸãƒ•ãƒ©ã‚°, çµ±è¨ˆæƒ…å ±)
        """
        start_time = datetime.now()
        stats = {
            'total_characters': len(text),
            'total_bytes': self._get_byte_size(text),
            'chunks': 0,
            'temp_files': [],
            'duration': 0
        }

        print("\n" + "="*60)
        print("ğŸ™ï¸ ã‚¹ãƒãƒ¼ãƒˆTTSéŸ³å£°ç”Ÿæˆã‚’é–‹å§‹")
        print("="*60)

        # SSMLåˆ¤å®š
        is_ssml = text.strip().startswith('<speak>') or '<break' in text

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡è„ˆè€ƒæ…®ã§åˆ†å‰²
        print("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æä¸­...")
        chunks = self.split_text_by_context(text, is_ssml)
        stats['chunks'] = len(chunks)

        print(f"ğŸ“Š çµ±è¨ˆ:")
        print(f"  - ç·æ–‡å­—æ•°: {stats['total_characters']:,}")
        print(f"  - ç·ãƒã‚¤ãƒˆæ•°: {stats['total_bytes']:,}")
        print(f"  - ãƒãƒ£ãƒ³ã‚¯æ•°: {stats['chunks']}")

        # å„ãƒãƒ£ãƒ³ã‚¯ã®éŸ³å£°ã‚’ç”Ÿæˆ
        temp_files = self.generate_audio_chunks(chunks, voice_config, is_ssml)
        stats['temp_files'] = temp_files

        if not temp_files:
            print("âŒ éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False, stats

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
        success = self.merge_audio_files(temp_files, output_path)

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if cleanup and temp_files:
            print("ğŸ§¹ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ä¸­...")
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                except:
                    pass

        # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
        end_time = datetime.now()
        stats['duration'] = (end_time - start_time).total_seconds()

        if success:
            file_size = os.path.getsize(output_path) / 1024  # KB
            print(f"\nğŸ‰ ç”Ÿæˆå®Œäº†ï¼")
            print(f"  ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
            print(f"  ğŸ“Š ã‚µã‚¤ã‚º: {file_size:.2f} KB")
            print(f"  â±ï¸ å‡¦ç†æ™‚é–“: {stats['duration']:.2f}ç§’")

            # ã‚³ã‚¹ãƒˆæ¨å®š
            cost_wavenet = stats['total_characters'] * (16.00 / 1_000_000)
            print(f"  ğŸ’° æ¨å®šã‚³ã‚¹ãƒˆ: ${cost_wavenet:.4f} (WaveNet)")
            print(f"  ğŸ“¢ ç„¡æ–™æ æ®‹ã‚Š: {1_000_000 - stats['total_characters']:,} æ–‡å­—/æœˆ")

        return success, stats


def create_workflow_integration():
    """git-worktree-agentãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¸ã®çµ±åˆç”¨é–¢æ•°"""

    integration_code = '''
# git-worktree-agentã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«çµ±åˆ

from tts_smart_generator import SmartTTSGenerator

def generate_project_narration(project_data):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è§£èª¬éŸ³å£°ã‚’ç”Ÿæˆ"""

    # å°æœ¬ã‚’æº–å‚™ï¼ˆSSMLã¾ãŸã¯Markdownï¼‰
    script_path = project_data.get('narration_script', 'docs/narration_script.ssml')
    output_path = project_data.get('output_path', 'docs/narration.mp3')

    # å°æœ¬ã‚’èª­ã¿è¾¼ã¿
    with open(script_path, 'r', encoding='utf-8') as f:
        script = f.read()

    # ã‚¹ãƒãƒ¼ãƒˆTTSã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
    tts = SmartTTSGenerator()

    # éŸ³å£°ã‚’ç”Ÿæˆï¼ˆè‡ªå‹•çš„ã«åˆ†å‰²ãƒ»çµåˆï¼‰
    success, stats = tts.generate_from_text(
        text=script,
        output_path=output_path,
        voice_config={
            'language_code': 'ja-JP',
            'name': 'ja-JP-Wavenet-B',
            'speaking_rate': 1.0,
            'pitch': 0.0
        }
    )

    if success:
        print(f"âœ… è§£èª¬éŸ³å£°ã‚’ç”Ÿæˆ: {output_path}")
        # HTMLãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«éŸ³å£°ã‚’çµ„ã¿è¾¼ã¿
        update_html_with_audio(output_path)

    return success

# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ç™»éŒ²
workflow_tasks.append({
    "id": "DOCS-3",
    "name": "è§£èª¬éŸ³å£°ç”Ÿæˆ",
    "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è§£èª¬éŸ³å£°ã‚’è‡ªå‹•ç”Ÿæˆ",
    "dependencies": ["DOCS-1", "DOCS-2"],  # HTMLã¨Scriptç”Ÿæˆå¾Œ
    "action": generate_project_narration
})
'''

    # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    with open('/Users/tsujisouhei/Desktop/git-worktree-agent/src/workflow_tts_integration.py', 'w') as f:
        f.write(integration_code)

    print("\nğŸ“ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("SmartTTSGenerator ãƒ†ã‚¹ãƒˆ")

    # 3Dã‚²ãƒ¼ãƒ ã®å°æœ¬ã§ãƒ†ã‚¹ãƒˆ
    tts = SmartTTSGenerator()

    # SSMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    ssml_path = "/Users/tsujisouhei/Desktop/3d-shooting-game/docs/narration_script.ssml"
    if os.path.exists(ssml_path):
        with open(ssml_path, 'r', encoding='utf-8') as f:
            script = f.read()

        # 1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«çµåˆã—ã¦ç”Ÿæˆ
        success, stats = tts.generate_from_text(
            text=script,
            output_path="/Users/tsujisouhei/Desktop/3d-shooting-game/docs/narration_complete.mp3"
        )

        if success:
            print("\nğŸ§ éŸ³å£°ã‚’å†ç”Ÿ:")
            print("open /Users/tsujisouhei/Desktop/3d-shooting-game/docs/narration_complete.mp3")