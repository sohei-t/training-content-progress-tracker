#!/usr/bin/env python3
"""
è‡ªå¾‹çš„æ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
ãƒ†ã‚¹ãƒˆå¤±æ•—ã‚’æ¤œå‡ºã—ã€è‡ªå‹•çš„ã«ä¿®æ­£ã‚’ç¹°ã‚Šè¿”ã™
"""

import json
import subprocess
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ImprovementLoopController:
    """
    æ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
    """

    def __init__(self, project_path: str, max_iterations: int = 3):
        """
        åˆæœŸåŒ–

        Args:
            project_path: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹
            max_iterations: æœ€å¤§ãƒ«ãƒ¼ãƒ—å›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3å›ï¼‰
        """
        self.project_path = Path(project_path)
        self.max_iterations = max_iterations
        self.iteration_count = 0
        self.test_results = []
        self.improvement_history = []

        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.log_dir = self.project_path / "logs" / "improvement"
        self.log_dir.mkdir(parents=True, exist_ok=True)

    def run_improvement_cycle(self) -> Dict:
        """
        æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ

        Returns:
            æœ€çµ‚çµæœã®è¾æ›¸
        """
        logger.info("ğŸ”„ æ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™")

        for iteration in range(1, self.max_iterations + 1):
            self.iteration_count = iteration
            logger.info(f"\n--- Iteration {iteration}/{self.max_iterations} ---")

            # 1. ãƒ†ã‚¹ãƒˆè©•ä¾¡
            test_result = self.evaluate_tests()
            self.test_results.append(test_result)

            # 2. æˆåŠŸåˆ¤å®š
            if test_result['overall_status'] == 'pass':
                logger.info("âœ… å…¨ãƒ†ã‚¹ãƒˆãŒãƒ‘ã‚¹ã—ã¾ã—ãŸï¼")
                return self._create_success_report()

            # 3. æœ€çµ‚å›ã®å ´åˆ
            if iteration == self.max_iterations:
                logger.warning("âš ï¸ æœ€å¤§è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸ")
                return self._create_partial_success_report()

            # 4. æ”¹å–„è¨ˆç”»ä½œæˆ
            improvement_plan = self.create_improvement_plan(test_result)

            # 5. ã‚³ãƒ¼ãƒ‰ä¿®æ­£
            fix_result = self.apply_fixes(improvement_plan)

            # å±¥æ­´ã«è¿½åŠ 
            self.improvement_history.append({
                'iteration': iteration,
                'test_result': test_result,
                'improvement_plan': improvement_plan,
                'fix_result': fix_result
            })

            # å°‘ã—å¾…æ©Ÿï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®åŒæœŸå¾…ã¡ï¼‰
            time.sleep(2)

        return self._create_partial_success_report()

    def evaluate_tests(self) -> Dict:
        """
        ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã€çµæœã‚’è©•ä¾¡

        Returns:
            ãƒ†ã‚¹ãƒˆçµæœã®è¾æ›¸
        """
        logger.info("ğŸ” ãƒ†ã‚¹ãƒˆã‚’è©•ä¾¡ä¸­...")

        # ãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ã‚’æ¤œå‡º
        test_command = self._detect_test_command()

        if not test_command:
            return {
                'overall_status': 'error',
                'message': 'ãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“',
                'timestamp': datetime.now().isoformat()
            }

        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        result = subprocess.run(
            test_command,
            shell=True,
            cwd=self.project_path,
            capture_output=True,
            text=True
        )

        # ãƒ­ã‚°ä¿å­˜
        log_file = self.log_dir / f"test_{self.iteration_count}.log"
        with open(log_file, 'w') as f:
            f.write(f"Command: {test_command}\n")
            f.write(f"Return Code: {result.returncode}\n")
            f.write(f"STDOUT:\n{result.stdout}\n")
            f.write(f"STDERR:\n{result.stderr}\n")

        # çµæœè§£æ
        return self._analyze_test_output(result, log_file)

    def _detect_test_command(self) -> Optional[str]:
        """
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é©ã—ãŸãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ã‚’æ¤œå‡º
        """
        # package.jsonãŒã‚ã‚‹å ´åˆï¼ˆNode.jsï¼‰
        package_json = self.project_path / "package.json"
        if package_json.exists():
            with open(package_json) as f:
                package_data = json.load(f)
                if 'scripts' in package_data and 'test' in package_data['scripts']:
                    return "npm test"

        # requirements.txtãŒã‚ã‚‹å ´åˆï¼ˆPythonï¼‰
        requirements = self.project_path / "requirements.txt"
        if requirements.exists():
            # pytestãŒä¸€èˆ¬çš„
            return "python -m pytest"

        # MakefileãŒã‚ã‚‹å ´åˆ
        makefile = self.project_path / "Makefile"
        if makefile.exists():
            with open(makefile) as f:
                if 'test:' in f.read():
                    return "make test"

        return None

    def _analyze_test_output(self, result: subprocess.CompletedProcess, log_file: Path) -> Dict:
        """
        ãƒ†ã‚¹ãƒˆå‡ºåŠ›ã‚’è§£æ
        """
        output = result.stdout + result.stderr

        # æˆåŠŸ/å¤±æ•—ã®åˆ¤å®š
        if result.returncode == 0:
            status = 'pass'
        else:
            status = 'fail'

        # å¤±æ•—ãƒ†ã‚¹ãƒˆã®æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        failed_tests = []
        if status == 'fail':
            lines = output.split('\n')
            for i, line in enumerate(lines):
                if 'FAIL' in line or 'ERROR' in line or 'âœ—' in line:
                    failed_tests.append({
                        'line': line.strip(),
                        'context': lines[max(0, i-2):min(len(lines), i+3)]
                    })

        return {
            'overall_status': status,
            'return_code': result.returncode,
            'failed_tests': failed_tests,
            'log_file': str(log_file),
            'timestamp': datetime.now().isoformat()
        }

    def create_improvement_plan(self, test_result: Dict) -> Dict:
        """
        ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰æ”¹å–„è¨ˆç”»ã‚’ä½œæˆ
        """
        logger.info("ğŸ“‹ æ”¹å–„è¨ˆç”»ã‚’ä½œæˆä¸­...")

        plan = {
            'iteration': self.iteration_count,
            'created_at': datetime.now().isoformat(),
            'issues': [],
            'fixes': []
        }

        # å¤±æ•—ãƒ†ã‚¹ãƒˆã‹ã‚‰å•é¡Œã‚’ç‰¹å®š
        for failed_test in test_result.get('failed_tests', []):
            issue = self._analyze_failure(failed_test)
            plan['issues'].append(issue)

            # ä¿®æ­£æ¡ˆã‚’ç”Ÿæˆ
            fix = self._generate_fix_suggestion(issue)
            plan['fixes'].append(fix)

        # è¨ˆç”»ã‚’ä¿å­˜
        plan_file = self.log_dir / f"plan_{self.iteration_count}.json"
        with open(plan_file, 'w') as f:
            json.dump(plan, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ“ {len(plan['fixes'])}å€‹ã®ä¿®æ­£æ¡ˆã‚’ä½œæˆã—ã¾ã—ãŸ")

        return plan

    def _analyze_failure(self, failed_test: Dict) -> Dict:
        """
        å¤±æ•—ã‚’åˆ†æ
        """
        line = failed_test['line']

        # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
        error_type = 'unknown'
        if 'TypeError' in line:
            error_type = 'type_error'
        elif 'ReferenceError' in line or 'NameError' in line:
            error_type = 'reference_error'
        elif 'SyntaxError' in line:
            error_type = 'syntax_error'
        elif 'AssertionError' in line or 'Expected' in line:
            error_type = 'assertion_error'

        return {
            'type': error_type,
            'description': line,
            'context': failed_test.get('context', [])
        }

    def _generate_fix_suggestion(self, issue: Dict) -> Dict:
        """
        ä¿®æ­£æ¡ˆã‚’ç”Ÿæˆ
        """
        fix = {
            'issue_type': issue['type'],
            'priority': 'high',
            'suggestion': ''
        }

        # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸä¿®æ­£æ¡ˆ
        if issue['type'] == 'type_error':
            fix['suggestion'] = 'å‹ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ ã—ã€é©åˆ‡ãªå‹å¤‰æ›ã‚’å®Ÿè£…'
        elif issue['type'] == 'reference_error':
            fix['suggestion'] = 'æœªå®šç¾©ã®å¤‰æ•°ãƒ»é–¢æ•°ã‚’å®šç¾©ã¾ãŸã¯ import ã‚’è¿½åŠ '
        elif issue['type'] == 'syntax_error':
            fix['suggestion'] = 'æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£'
        elif issue['type'] == 'assertion_error':
            fix['suggestion'] = 'ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¦‹ç›´ã—ã€æœŸå¾…ã•ã‚Œã‚‹å€¤ã‚’è¿”ã™ã‚ˆã†ä¿®æ­£'
        else:
            fix['suggestion'] = 'ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ†æã—ã€é©åˆ‡ãªä¿®æ­£ã‚’å®Ÿæ–½'

        return fix

    def apply_fixes(self, improvement_plan: Dict) -> Dict:
        """
        æ”¹å–„è¨ˆç”»ã«åŸºã¥ã„ã¦ä¿®æ­£ã‚’é©ç”¨

        æ³¨: å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã¯Fixerã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ‹…å½“
        ã“ã“ã§ã¯ãã®çµæœã‚’è¨˜éŒ²
        """
        logger.info("ğŸ”§ ä¿®æ­£ã‚’é©ç”¨ä¸­...")

        result = {
            'iteration': self.iteration_count,
            'fixes_applied': len(improvement_plan['fixes']),
            'timestamp': datetime.now().isoformat()
        }

        # ä¿®æ­£çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        fix_log = self.log_dir / f"fixes_{self.iteration_count}.json"
        with open(fix_log, 'w') as f:
            json.dump(result, f, indent=2)

        logger.info(f"âœï¸ {result['fixes_applied']}å€‹ã®ä¿®æ­£ã‚’é©ç”¨ã—ã¾ã—ãŸ")

        return result

    def _create_success_report(self) -> Dict:
        """
        æˆåŠŸãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
        """
        report = {
            'status': 'success',
            'message': 'å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒãƒ‘ã‚¹ã—ã¾ã—ãŸ',
            'total_iterations': self.iteration_count,
            'test_results': self.test_results,
            'improvement_history': self.improvement_history,
            'timestamp': datetime.now().isoformat()
        }

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        self._save_report(report, 'success_report.json')

        return report

    def _create_partial_success_report(self) -> Dict:
        """
        éƒ¨åˆ†æˆåŠŸãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
        """
        # æœ€å¾Œã®ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰æˆåŠŸç‡ã‚’è¨ˆç®—
        last_result = self.test_results[-1] if self.test_results else {}

        report = {
            'status': 'partial_success',
            'message': 'ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸãŒã€æ”¹å–„ã‚’å®Ÿæ–½ã—ã¾ã—ãŸ',
            'total_iterations': self.iteration_count,
            'remaining_issues': last_result.get('failed_tests', []),
            'test_results': self.test_results,
            'improvement_history': self.improvement_history,
            'timestamp': datetime.now().isoformat(),
            'known_limitations': self._generate_known_limitations()
        }

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        self._save_report(report, 'partial_success_report.json')

        return report

    def _generate_known_limitations(self) -> List[str]:
        """
        æ—¢çŸ¥ã®åˆ¶ç´„ã‚’ç”Ÿæˆ
        """
        limitations = []

        if self.test_results:
            last_result = self.test_results[-1]
            for failed_test in last_result.get('failed_tests', []):
                limitations.append(f"æœªè§£æ±º: {failed_test.get('line', 'Unknown test failure')}")

        return limitations

    def _save_report(self, report: Dict, filename: str):
        """
        ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
        """
        report_file = self.log_dir / filename
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_file}")


def main():
    """
    CLIå®Ÿè¡Œç”¨
    """
    import argparse

    parser = argparse.ArgumentParser(description='è‡ªå¾‹çš„æ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼')
    parser.add_argument('project_path', help='ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹')
    parser.add_argument('--max-iterations', type=int, default=3, help='æœ€å¤§ãƒ«ãƒ¼ãƒ—å›æ•°')

    args = parser.parse_args()

    controller = ImprovementLoopController(
        project_path=args.project_path,
        max_iterations=args.max_iterations
    )

    result = controller.run_improvement_cycle()

    # çµæœã‚’è¡¨ç¤º
    print(f"\n{'='*50}")
    print(f"Status: {result['status']}")
    print(f"Message: {result['message']}")
    print(f"Iterations: {result['total_iterations']}")

    if result['status'] == 'partial_success':
        print(f"\næ—¢çŸ¥ã®åˆ¶ç´„:")
        for limitation in result.get('known_limitations', []):
            print(f"  - {limitation}")


if __name__ == "__main__":
    main()