#!/usr/bin/env python3
"""
Workflow Orchestrator - è‡ªå¾‹å‹ä¸¦åˆ—å‡¦ç†å¯¾å¿œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ 
Version 6.0 - Autonomous Parallel Workflow System

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œã—ã€
ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹é«˜é€ŸåŒ–ã¨è‡ªå¾‹çš„ãªå“è³ªæ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
"""

import os
import sys
import json
import yaml
import time
import subprocess
import threading
import queue
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TaskStatus(Enum):
    """ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

class AgentType(Enum):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ—"""
    REQUIREMENTS = "requirements_analyst"
    PLANNER = "planner"
    ARCHITECT = "architect"
    TEST_DESIGNER = "test_designer"
    UI_DESIGNER = "ui_designer"
    FRONTEND = "frontend_dev"
    BACKEND = "backend_dev"
    DATABASE = "db_expert"
    EVALUATOR = "evaluator"
    IMPROVEMENT_PLANNER = "improvement_planner"
    FIXER = "fixer"
    GATEKEEPER = "gatekeeper"
    DOCUMENTER = "documenter"
    LAUNCHER = "launcher_creator"
    REVIEWER = "reviewer"
    GENERALIST = "generalist"
    # Game-specific agents
    GAME_DESIGN = "game_design"
    ASSET_REQUIREMENTS = "asset_requirements"
    CORE_GAME_LOGIC = "core_game_logic"
    ASSET_INTEGRATION = "asset_integration"
    UI_HUD = "ui_hud"
    GAME_INTEGRATION = "game_integration"
    PLAYTEST = "playtest"
    BALANCE_TUNING = "balance_tuning"
    MOBILE_GAMING_SPECIALIST = "mobile_gaming_specialist"  # NEW!

@dataclass
class Task:
    """ã‚¿ã‚¹ã‚¯å®šç¾©"""
    id: str
    name: str
    agent: AgentType
    description: str
    dependencies: List[str] = field(default_factory=list)
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[Dict] = None
    error: Optional[str] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None

    @property
    def duration(self) -> Optional[float]:
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return None

@dataclass
class WorkflowPhase:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚§ãƒ¼ã‚º"""
    name: str
    agents: List[AgentType]
    parallel: bool = False
    max_iterations: int = 1
    success_criteria: Optional[str] = None
    tasks: List[Task] = field(default_factory=list)

class WorkflowOrchestrator:
    """
    ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼
    è‡ªå¾‹çš„ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èµ·å‹•ã—ã€ä¸¦åˆ—å‡¦ç†ã‚’ç®¡ç†
    """

    def __init__(self, config_path: str = "agent_config.yaml"):
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.task_queue = queue.Queue()
        self.results = {}
        self.executor = ThreadPoolExecutor(max_workers=3)
        self.current_worktree = None

    def _load_config(self) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if not self.config_path.exists():
            raise FileNotFoundError(f"Config file not found: {self.config_path}")

        with open(self.config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def execute_workflow(self, workflow_name: str, project_name: str) -> Dict:
        """
        ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ

        Args:
            workflow_name: å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å
            project_name: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå

        Returns:
            å®Ÿè¡Œçµæœã®ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒª
        """
        logger.info(f"ğŸš€ Starting workflow: {workflow_name} for project: {project_name}")

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã‚’å–å¾—
        workflow_def = self.config['workflows'].get(workflow_name)
        if not workflow_def:
            raise ValueError(f"Workflow not found: {workflow_name}")

        # Worktreeä½œæˆ
        self.current_worktree = self._create_worktree(project_name)

        try:
            # ãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã«å®Ÿè¡Œ
            results = {}
            phases = workflow_def.get('phases', [])

            for phase_def in phases:
                phase = WorkflowPhase(
                    name=phase_def['phase'],
                    agents=[AgentType(a) for a in phase_def['agents']],
                    parallel=phase_def.get('parallel', False),
                    max_iterations=phase_def.get('max_iterations', 1),
                    success_criteria=phase_def.get('success_criteria')
                )

                logger.info(f"ğŸ“‹ Executing phase: {phase.name}")
                phase_result = self._execute_phase(phase)
                results[phase.name] = phase_result

                # æ”¹å–„ãƒ«ãƒ¼ãƒ—ã®å ´åˆã€æˆåŠŸã™ã‚‹ã¾ã§ç¹°ã‚Šè¿”ã—
                if phase.name == "æ”¹å–„ãƒ«ãƒ¼ãƒ—":
                    iteration = 1
                    while iteration < phase.max_iterations:
                        if self._check_success_criteria(phase_result, phase.success_criteria):
                            break

                        logger.info(f"ğŸ”„ Improvement iteration {iteration + 1}/{phase.max_iterations}")
                        phase_result = self._execute_phase(phase)
                        results[f"{phase.name}_iteration_{iteration + 1}"] = phase_result
                        iteration += 1

            # æˆæœç‰©ã‚’ãƒãƒ¼ã‚¸
            if not workflow_def.get('auto_merge', True):
                logger.info("âš ï¸ Auto-merge disabled. Manual merge required.")
            else:
                self._merge_results(project_name)

            return {
                'status': 'success',
                'workflow': workflow_name,
                'project': project_name,
                'worktree': str(self.current_worktree),
                'phases': results,
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"âŒ Workflow execution failed: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'workflow': workflow_name,
                'project': project_name,
                'timestamp': datetime.now().isoformat()
            }

    def _create_worktree(self, project_name: str) -> Path:
        """Git Worktreeã‚’ä½œæˆ"""
        worktree_path = Path(f"./worktrees/mission-{project_name}")

        if worktree_path.exists():
            logger.warning(f"Worktree already exists: {worktree_path}")
            return worktree_path

        # git worktree add -b feat/{project_name} ./worktrees/mission-{project_name} main
        cmd = [
            "git", "worktree", "add",
            "-b", f"feat/{project_name}",
            str(worktree_path),
            "main"
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            raise RuntimeError(f"Failed to create worktree: {result.stderr}")

        logger.info(f"âœ… Created worktree: {worktree_path}")
        return worktree_path

    def _execute_phase(self, phase: WorkflowPhase) -> Dict:
        """ãƒ•ã‚§ãƒ¼ã‚ºã‚’å®Ÿè¡Œï¼ˆä¸¦åˆ—/ç›´åˆ—å‡¦ç†å¯¾å¿œï¼‰"""
        phase_start = datetime.now()

        # ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆ
        tasks = []
        for i, agent in enumerate(phase.agents):
            task = Task(
                id=f"{phase.name}_{agent.value}_{i}",
                name=f"{agent.value} task",
                agent=agent,
                description=f"Execute {agent.value} for {phase.name}"
            )
            tasks.append(task)

        # å®Ÿè¡Œï¼ˆä¸¦åˆ—ã¾ãŸã¯ç›´åˆ—ï¼‰
        if phase.parallel:
            results = self._execute_parallel(tasks)
        else:
            results = self._execute_serial(tasks)

        phase_end = datetime.now()

        return {
            'phase': phase.name,
            'parallel': phase.parallel,
            'tasks': [self._task_to_dict(t) for t in tasks],
            'duration': (phase_end - phase_start).total_seconds(),
            'success': all(t.status == TaskStatus.COMPLETED for t in tasks)
        }

    def _execute_parallel(self, tasks: List[Task]) -> Dict:
        """ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ"""
        logger.info(f"âš¡ Executing {len(tasks)} tasks in parallel")

        futures = {}
        for task in tasks:
            future = self.executor.submit(self._execute_task, task)
            futures[future] = task

        # çµæœã‚’åé›†
        results = {}
        for future in as_completed(futures):
            task = futures[future]
            try:
                result = future.result()
                task.status = TaskStatus.COMPLETED
                task.result = result
                results[task.id] = result
                logger.info(f"âœ… Task completed: {task.name}")
            except Exception as e:
                task.status = TaskStatus.FAILED
                task.error = str(e)
                logger.error(f"âŒ Task failed: {task.name} - {e}")

        return results

    def _execute_serial(self, tasks: List[Task]) -> Dict:
        """ã‚¿ã‚¹ã‚¯ã‚’ç›´åˆ—å®Ÿè¡Œ"""
        logger.info(f"ğŸ“ Executing {len(tasks)} tasks serially")

        results = {}
        for task in tasks:
            try:
                result = self._execute_task(task)
                task.status = TaskStatus.COMPLETED
                task.result = result
                results[task.id] = result
                logger.info(f"âœ… Task completed: {task.name}")
            except Exception as e:
                task.status = TaskStatus.FAILED
                task.error = str(e)
                logger.error(f"âŒ Task failed: {task.name} - {e}")
                break  # ç›´åˆ—å®Ÿè¡Œã§ã¯å¤±æ•—æ™‚ã«åœæ­¢

        return results

    def _execute_task(self, task: Task) -> Dict:
        """å€‹åˆ¥ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèµ·å‹•ï¼‰"""
        task.start_time = datetime.now()
        task.status = TaskStatus.RUNNING

        logger.info(f"ğŸ¤– Launching agent: {task.agent.value}")

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’å–å¾—
        agent_config = self.config['agents'].get(task.agent.value, {})

        # Claudeã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦Taskãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆ
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Claude APIã‚’ç›´æ¥å‘¼ã³å‡ºã™ã‹ã€
        # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§Claude CLIã‚’å®Ÿè¡Œ

        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã«ã¯Claude APIã‚’å‘¼ã¶ï¼‰
        time.sleep(2)  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

        task.end_time = datetime.now()

        # çµæœã‚’è¿”ã™ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        return {
            'agent': task.agent.value,
            'status': 'completed',
            'duration': task.duration,
            'output': f"Output from {task.agent.value}",
            'files_created': [],
            'tests_passed': True if 'test' in task.agent.value else None
        }

    def _check_success_criteria(self, phase_result: Dict, criteria: Optional[str]) -> bool:
        """æˆåŠŸåŸºæº–ã‚’ãƒã‚§ãƒƒã‚¯"""
        if not criteria:
            return True

        if criteria == "all_tests_pass":
            # ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            for task in phase_result.get('tasks', []):
                if task.get('tests_passed') is False:
                    return False
            return True

        return True

    def _merge_results(self, project_name: str):
        """æˆæœç‰©ã‚’ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ©ãƒ³ãƒã«ãƒãƒ¼ã‚¸"""
        logger.info("ğŸ”€ Merging results to main branch")

        # git merge feat/{project_name}
        cmd = ["git", "merge", f"feat/{project_name}"]
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            logger.error(f"Merge failed: {result.stderr}")
            raise RuntimeError("Failed to merge results")

        logger.info("âœ… Successfully merged to main branch")

    def _task_to_dict(self, task: Task) -> Dict:
        """ã‚¿ã‚¹ã‚¯ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            'id': task.id,
            'name': task.name,
            'agent': task.agent.value,
            'status': task.status.value,
            'duration': task.duration,
            'error': task.error
        }

    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.executor.shutdown(wait=True)

        if self.current_worktree and self.current_worktree.exists():
            # git worktree remove
            cmd = ["git", "worktree", "remove", str(self.current_worktree)]
            subprocess.run(cmd, capture_output=True, text=True)
            logger.info(f"ğŸ§¹ Cleaned up worktree: {self.current_worktree}")


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    import argparse

    parser = argparse.ArgumentParser(description='Workflow Orchestrator')
    parser.add_argument('workflow', help='Workflow name to execute')
    parser.add_argument('project', help='Project name')
    parser.add_argument('--config', default='agent_config.yaml', help='Config file path')

    args = parser.parse_args()

    # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œ
    orchestrator = WorkflowOrchestrator(args.config)

    try:
        result = orchestrator.execute_workflow(args.workflow, args.project)

        # çµæœã‚’è¡¨ç¤º
        print("\n" + "="*60)
        print("ğŸ“Š WORKFLOW EXECUTION REPORT")
        print("="*60)
        print(json.dumps(result, indent=2, ensure_ascii=False))

    finally:
        orchestrator.cleanup()


if __name__ == "__main__":
    main()